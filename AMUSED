#!/usr/bin/ruby
require "NMERTREE.rb"
require "UTILS.rb";
require "SWITCHES.rb"
require "GZ.rb"

NUMARGV=4;
if ARGV.length()<NUMARGV  || ARGV[0]=~/^--?[h?]/ #TODO: clean
	print("Usage: AMUSED -q <inFPQuery>  -o <outFP> [-b <inFPBG> | -r <randomizeNMer>] [-s <maxTreeSize>]\n");
	print("  -q <inFPQuery> = query sequences\n");
	print("  -b <inFPBG> = compare seqs to these background seqs\n");
	print("  -bp <bgPseudo> = pseudocount to add to background [default=0.5]\n");
	print("  -o <outFP> = output file\n");
	print("  -s <maxTreeSize> = max n-mer to consider [default=8]\n");
	print("  -z <subZCutoff> = minimum absolute Sub-Z-score [default = 0; print all]\n");
	print("  -t <numThreads> = number of CPU threads to use [default=1]\n");
	print("  -1p = sequences not in fasta format: each line is a full sequence\n");
	print("  -ng = no inserting gaps\n");
	print("  -nu = no changing to upper case before scan (non ATGC bases are discarded)\n");
	print("  -ds = double stranded (reverse complement sequences too)\n");
	print("  -ns = don't sort\n");
	print("  -bc = add lines to output for base content\n");
	print("  -nsz = don't calculate super Zs\n");
	exit;
end

switches = parseSwitches(ARGV,{"s"=>1,'z'=>1,'o'=>1,'q'=>1,'b'=>1,'ds'=>1,'bp'=>1,'nsz'=>0,'ng'=>0,'t'=>1, '1p'=>0,'ns'=>0, 'nu'=>0, 'bc'=>0});
switches=getDefaults(switches,{"s"=>8,'z'=>0,'bp'=>'0.5','t'=>"1"});
numThreads = switches['t'].to_i();
numThreads = [numThreads,1].max();
maxTreeSize=switches['s'].to_f();
bgPhi = switches['bp'].to_f();
fgInFP = switches['q'];
bgInFP = switches['b'];
useBG = !bgInFP.nil?;
addGaps = switches['ng'].nil?;
outFP = switches['o'];
doubleStranded=!switches['ds'].nil?
isFasta=switches['1p'].nil?
noSort = !switches['ns'].nil?
toUpper = switches['nu'].nil?
superZ=switches['nsz'].nil?();
addBC = !switches['bc'].nil?();
minSubZ = switches['z'].to_i();
if superZ
	superZ=1;
else
	superZ=0;
end

alphabet = ["A","T","G","C"];

#initialize background
if useBG
	print("Scanning background sequences\n");
	gapCountBG = NMerTreeHash.new(maxTreeSize+superZ,alphabet);
	bgCount=0;
	bgTotLen=0;
	t1 = Thread.new{
		bgSR =SeqReader.new(smartGZIn(bgInFP,"r"),isFasta, toUpper);
		bgCount, bgTotLen = gapCountBG.traverseSeqs(bgSR);
		#print("bgTotLen = " + bgTotLen.to_s()+"\n");
	}
	if (numThreads==1)
		t1.join();
	end
end
#initialize foreground
print("Scanning foreground sequences\n");
gapCountFG =NMerTreeHash.new(maxTreeSize+superZ,alphabet);
fgSR =SeqReader.new(smartGZIn(fgInFP,"r"),isFasta, toUpper);
seqCount, seqTotLen = gapCountFG.traverseSeqs(fgSR);
#print("seqCount = " + seqCount.to_s()+"\n");
if useBG
	t1.join()
end

print("Input All Data, All Trees Built.\n");
alphanum=Hash.new();
0.upto(alphabet.length()-1){|i|
	alphanum[alphabet[i]]=i;
}

headerI = 0;
I_K = 0; I_SEQ = 1; I_RC = 2; I_Num_FG=3; I_Size_FG=4; I_Pct_FG=5; I_SubEnr_FG=6; I_SubDepl_FG=7; I_SubZ_FG=8; 
headerI=9;
header=[];
header.push("k","kMer", "kMerRC", "Num_FG", "Size_FG","Pct_FG"); #general headers
header.push("SubEnr_FG","SubDepl_FG","SubZ_FG"); # Z-score 
if useBG
	I_Num_BG= headerI+0; I_Size_BG = headerI+1; I_Pct_BG = headerI+2; I_SubEnr_BG = headerI+3; I_SubDepl_BG = headerI+4; I_SubZ_BG = headerI+5; I_SubEnr_Rel=headerI+6; I_SubDepl_Rel = headerI+7; I_SubZ_Rel = headerI + 8; headerI = headerI+9;
	header.push("Num_BG","Size_BG","Pct_BG","SubEnr_BG","SubDepl_BG","SubZ_BG", "SubEnr_Rel","SubDepl_Rel","SubZ_Rel"); # with background
end
if superZ==1
	I_SuperZ_FG = headerI+0; I_DeltaZ_FG = headerI+1; headerI+=2;
	header.push("SuperZ_FG","DeltaZ_FG"); # super Z scores
	if useBG
		I_SuperZ_BG = headerI+0; I_SuperZ_Rel = headerI+1; I_DeltaZ_Rel = headerI+2; headerI+=3
		header.push("SuperZ_BG","SuperZ_Rel","DeltaZ_Rel"); #With background
	end
end
NUMFIELDS=headerI;
dataPositions = Hash.new();
0.upto(header.length()-1){|i|
	dataPositions[header[i]]=i;
}


#print("Calculating base content \n");
ntContent=gapCountFG.getAllNMers(1,alphabet);
if doubleStranded
	seqTotLen+=seqTotLen;
	bgTotLen+=bgTotLen if useBG;
	seqCount+=seqCount;
	bgCount+=bgCount if useBG;
end
ntHash=Hash.new();
ntContent.each{|b,n|
	if doubleStranded
		ntHash[b]=(0.0+n+gapCountFG[revcomp(b)])/seqTotLen;
	else
		ntHash[b]=(0.0+n)/seqTotLen;
	end
}
if superZ==1 && useBG
	ntContentBG=gapCountBG.getAllNMers(1,alphabet);
	ntHashBG=Hash.new();
	ntContentBG.each{|b,n|
		if doubleStranded
			ntHashBG[b]=(0.0+n+gapCountBG[revcomp(b)])/bgTotLen;
		else
			ntHashBG[b]=(0.0+n)/bgTotLen;
		end
	}
end
allKMerTotalsFG=[];
allKMerTotalsBG=[] if useBG;

#print("Calculating K and N \n"); 
1.upto(maxTreeSize+superZ){|k|
	allKMerTotalsFG[k] = seqTotLen-(seqCount*(k-1)); # total num k-mers in sequence
	if useBG
		allKMerTotalsBG[k] = bgTotLen-(bgCount*(k-1)); # total num k-mers in background
	end
}


#require "profile.rb"
#require "benchmark"
#puts Benchmark.measure(){
if addGaps
	print("Adding gaps...\n");
#	puts Benchmark.measure(){
	#TODO: add multithreading to this section, but do it deeper than this since the biggest k takes by far the longest
	#Also, since each k depends on k-1, you must do them in order.
	3.upto(maxTreeSize + superZ){|k|
		#puts "k="+k.to_s()
		#for each k-mer for which there could be gaps
		oneLessGapMers=gapCountFG.keys(k);
		1.upto(k-2){|g|
			#puts " g="+g.to_s()
			#for each potential number of gaps
			# I will add g gaps to every k-mer
			sameNumGapMers = [];
			0.upto(oneLessGapMers.length()-1){|m|
				#puts "  m="+m.to_s()+" gkmer = "+oneLessGapMers[m]
				#for each k-mer with g-1 gaps, add one more gap
				1.upto(k-2){|p| 
					#puts "   p="+p.to_s()
					#for each position to which the gap could be added
					if oneLessGapMers[m][p,1]=="A" #{
						#Only add a gap if the position is an A because a gap (-) cannot be re-added and if I did it for ATGC, I would do it four times
						#need: 
						#1) expected counts for this gapped k-mer and expected counts when one base is removed from either side =>Z
						#2) counts for the four Mers where position P={ATGC}, expected counts for these with a terminal base removed => superZ
						curGappedKMer = oneLessGapMers[m].dup;
						curGappedKMer[p,1]="-";
						seqHits=0;
						alphabet.each(){|b|
						#	puts oneLessGapMers[m][0,p]+b+oneLessGapMers[m][p+1..-1]
							seqHits+=gapCountFG[oneLessGapMers[m][0,p]+b+oneLessGapMers[m][p+1..-1]];
						}
						gapCountFG[curGappedKMer]=seqHits;
						if useBG
							seqHitsBG=0;
							alphabet.each(){|b|
								seqHitsBG+=gapCountBG[oneLessGapMers[m][0,p]+b+oneLessGapMers[m][p+1..-1]];
							}
							gapCountBG[curGappedKMer]=seqHitsBG;
						end
						sameNumGapMers.push(curGappedKMer);
					end#}
				}
			}
			oneLessGapMers=sameNumGapMers;
		}
#	} #Benchmark
	}
end

print("Calculating statistics... \n");
#puts Benchmark.measure(){
allData = []; 
if doubleStranded
	didThese ={};
end
if addBC # include one line for the base content with only the relevant fields filled out
	ntContent.each{|b,n|
		curKMerData=[0] * headerI; #initialize to 0s
		curKMerData[I_K]=1;
		curKMerData[I_SEQ]=b;
		curKMerData[I_RC]=revcomp(b)
		#calc frequency as percent
		if (doubleStranded)
			next if (!didThese[b].nil?);
			didThese[revcomp(b)]=1;
		end
		curKMerData[I_Num_FG]=n
		curKMerData[I_Size_FG] = seqTotLen;
		curKMerData[I_Pct_FG] =100*ntHash[b];
		if useBG
			ntContentBG.each{|b2,n2|
				if b2==b
					curKMerData[I_Num_BG]=n2
				end
			}
			curKMerData[I_Size_BG] = bgTotLen;
			curKMerData[I_Pct_BG] =100*ntHashBG[b];
		end
		allData.push(curKMerData);
	}
end

nextI=0;
refNum=0;
2.upto(maxTreeSize){|k|
	curFGDist=gapCountFG.keys(k).sort();
	kMersTotalFG = allKMerTotalsFG[k]; # the total numer of k-mers in FG
	if useBG
		curBGDist=gapCountBG.keys(k).sort();
		kMersTotalBG = allKMerTotalsBG[k]; # the total number of k-mers in BG
		raise("The number of query and background #{k}-mers are different: #{curFGDist.length()} #{curBGDist.length()}") if curFGDist.length()!=curBGDist.length();
	end
	#printf("k = %d\n",k);
	0.upto(curFGDist.length-1){|i| # for each k-mer, i
		curKMerData=[];
		curKMerData[I_K]=k;
		seqNMer=curFGDist[i]
		seqHits = gapCountFG[seqNMer];
		if (doubleStranded)
			next if (!didThese[seqNMer].nil?);
			seqHits += gapCountFG[revcomp(seqNMer)];
			didThese[revcomp(seqNMer)]=1;
		end
		curKMerData[I_SEQ]=seqNMer;
		curKMerData[I_RC]=revcomp(seqNMer)
		curKMerData[I_Num_FG]=seqHits;
		curKMerData[I_Size_FG]=allKMerTotalsFG[k]
		curKMerData[I_Pct_FG]=(100.0*seqHits)/allKMerTotalsFG[k];
		refNum+=1;
		n1=seqNMer[0,1]; #first nucleotide
		n2=seqNMer[-1,1]; #last nucle
		s1=seqNMer[1,k-1]; #suffix (k-1)-mer sub-motif
		s2=seqNMer[0,k-1]; #prefix (k-1)-mer sub-motif
		subLenCorrFG1 = 1.0 * kMersTotalFG/allKMerTotalsFG[k-1]
		subLenCorrFG2 = 1.0 * kMersTotalFG/allKMerTotalsFG[k-1]
		#print("s1: "+s1+"\n");
		#print("s2: "+s2+"\n");
		kS = k-1
		while s1[0,1]=="-" #remove gaps
			s1=s1[1..-1];
			subLenCorrFG1 = subLenCorrFG1*allKMerTotalsFG[kS]/allKMerTotalsFG[kS-1]
			kS=kS-1;
		end
		kS = k-1
		while s2[-1,1]=="-" #remove gaps
			s2=s2[0..-2];
			subLenCorrFG2 = subLenCorrFG2*allKMerTotalsFG[kS]/allKMerTotalsFG[kS-1]
			kS=kS-1;
		end
			#although using s1.length instead of k-1 for the /allKMerTotalsBG index might seem to make sense, we actually are pretending this has terminal gaps and so k-1 should be used here too
		#puts("s1: "+s1+"\n");
		begin
		if doubleStranded
			e1=ntHash[n1]*(gapCountFG[s1]) + ntHash[revcomp(n1)]*gapCountFG[revcomp(s1)];#expected frequency of cur k-mer, given s1 frequency and n1
			e2=ntHash[n2]*(gapCountFG[s2]) + ntHash[revcomp(n2)]*gapCountFG[revcomp(s2)];# expected frequency of cur k-mer, given s2 frequency and n2
		else
			e1=ntHash[n1]*(gapCountFG[s1]);#expected frequency of cur k-mer, given s1 frequency and n1
			e2=ntHash[n2]*(gapCountFG[s2]);# expected frequency of cur k-mer, given s2 frequency and n2
		end
		rescue Exception => e
			puts s1
			puts s2
			puts gapCountFG[s1]
			puts gapCountFG[s2]
			raise e
		end
		eMax=[e1*subLenCorrFG1,e2*subLenCorrFG2].max(); # compare to max if enriched, as count
		dMin=[e1*subLenCorrFG1,e2*subLenCorrFG2].min(); # compare to min if depleted, as count
		if eMax==0 # (k-1)-mers do not occur
			curKMerData[I_SubEnr_FG]=1.0;
		else
			curKMerData[I_SubEnr_FG]=(0.0+seqHits)/eMax; #enrichment ratio
		end
		if dMin==0 # (k-1)-mers do not occur; in this case the k-mer is not any more depleted than we expect
			curKMerData[I_SubDepl_FG]=1.0;
		else
			curKMerData[I_SubDepl_FG]=(0.0+seqHits)/dMin; # depletion ratio
		end
		if seqHits>eMax # k-mer is enriched relative to enrichment sub-motif
			expected=eMax;
		elsif seqHits<dMin # k-mer is depleted relative to sub-motif
			expected=dMin;
		else #neither enriched nor depleted
			expected=seqHits;
		end
		justZScore=0.0;
		if expected!=0
			justZScore=(0.0+seqHits-expected)/(Math.sqrt(expected));
		end
		curKMerData[I_SubZ_FG]=justZScore;
		if useBG # calculate normalized z score {
			subLenCorrBG1 = 1.0 ;
			subLenCorrBG2 = 1.0 ;
			(k).downto(s1.length()+1){|kS|
				subLenCorrBG1=subLenCorrBG1*allKMerTotalsBG[kS]/allKMerTotalsBG[kS-1];
			}
			(k).downto(s2.length()+1){|kS|
				subLenCorrBG2=subLenCorrBG2*allKMerTotalsBG[kS]/allKMerTotalsBG[kS-1];
			}
			bgNMer = curBGDist[i];
			bgHits = gapCountBG[bgNMer];
			if (doubleStranded)
				bgHits += gapCountBG[revcomp(bgNMer)];
				e1b=ntHashBG[n1]*(gapCountBG[s1]) + ntHashBG[revcomp(n1)]*gapCountBG[revcomp(s1)];#expected freq of (k-1)-mer in BG, using sub-motif s1
				e2b=ntHashBG[n2]*(gapCountBG[s2]) + ntHashBG[revcomp(n2)]*gapCountBG[revcomp(s2)];# same for s2
			else
				#although using s1.length instead of k-1 for the /allKMerTotalsBG index might seem to make sense, we actually are pretending this has terminal gaps and so k-1 should be used here too
				e1b=ntHashBG[n1]*(gapCountBG[s1]);#expected freq of (k-1)-mer in BG, using sub-motif s1
				e2b=ntHashBG[n2]*(gapCountBG[s2]);# same for s2
			end
			raise("bgNMer and seqNMer are not the same! "+bgNMer+" "+seqNMer+" i="+i.to_s()) if bgNMer!=seqNMer;
			curKMerData[I_Num_BG]=bgHits;
			curKMerData[I_Pct_BG]=(100.0*bgHits)/allKMerTotalsBG[k];
			curKMerData[I_Size_BG]=allKMerTotalsBG[k];
			eMaxb=[e1b*subLenCorrBG1,e2b*subLenCorrBG2].max(); # expected count in background, if submotifs enriched
			dMinb=[e1b*subLenCorrBG1,e2b*subLenCorrBG2].min(); # expected count in background, if submotifs depleted
			if eMaxb==0
				curKMerData[I_SubEnr_BG]=1.0;
			else
				curKMerData[I_SubEnr_BG]=((0.0+bgHits)/eMaxb); 
			end
			if dMinb==0
				curKMerData[I_SubDepl_BG]=1.0;
			else
				curKMerData[I_SubDepl_BG]=((0.0+bgHits)/dMinb);
			end
			if bgHits>eMaxb #k-mer enriched in BG
				expectedB=eMaxb;
			elsif bgHits<dMinb #k-mer depleted in BG
				expectedB=dMinb;
			else
				expectedB=bgHits;
			end
			if expectedB==0
				curKMerData[I_SubZ_BG]=(0.0);
			else
				curKMerData[I_SubZ_BG]=((0.0+bgHits-expectedB)/Math.sqrt(expectedB));
			end
			if eMax==0 
				if seqHits!=0
					raise("Expected-enr is 0, but actual is not in FG: "+seqNMer);
				end
				curKMerData[I_SubEnr_Rel]=(0.0); 
			else
				curKMerData[I_SubEnr_Rel]=(((0.0+seqHits)/eMax)/((0.0+bgHits+bgPhi)/(eMaxb+bgPhi))); # ratio of ratios
			end
			if dMin==0 
				if seqHits!=0
					raise("Expected-depl is 0, but actual is not in FG: "+seqNMer);
				end
				# if there were no hits expected in the FG, the BG, or the BG had no hits this will be undef (/0 error)
				curKMerData[I_SubDepl_Rel]=(0.0); 
			else
				curKMerData[I_SubDepl_Rel]=(((0.0+seqHits)/dMin)/((0.0+bgHits+bgPhi)/(dMinb+bgPhi)));
			end
			
			if expected==0 # FG k-mer was expected 0 times
				normZScore=0.0; # numerator is undef (0/0)
			else
				if expected>expectedB
					denom = Math.sqrt(expectedB);
					scaleFG=expectedB/expected;
					scaleBG=1;
				else
					denom = Math.sqrt(expected);
					scaleFG=1;
					scaleBG=expected/expectedB;
				end
				denom=1 if denom==0;
				normZScore=((0.0+seqHits-expected)*scaleFG-((0.0+bgHits-expectedB)*scaleBG))/(denom); 
			end
			curKMerData[I_SubZ_Rel]=(normZScore);
		end #}
		if superZ==1 #{
			supZmax=0.0;
			supZmin=0.0;
			if seqHits==0 # if no instances of this motif, there can be no super motifs
				curKMerData[I_SuperZ_FG]=0.0;
			else
				alphabet.each{|b| 
					curExp=(0.0+seqHits)*ntHash[b]; #calculate most enriched and most depleted (k+1)-mer Z score given k-mer
					if curExp>0
						supZmax=[supZmax, (0.0+gapCountFG[seqNMer+b]-curExp)/Math.sqrt(curExp),(0.0+gapCountFG[b+seqNMer]-curExp)/Math.sqrt(curExp)].max();
						supZmin=[supZmin, (0.0+gapCountFG[seqNMer+b]-curExp)/Math.sqrt(curExp),(0.0+gapCountFG[b+seqNMer]-curExp)/Math.sqrt(curExp)].min();
						if addGaps # add a base of information to the middle
							1.upto(seqNMer.length()-2){|gp|
								if seqNMer[gp,1]=="-"
									supZmax=[supZmax, (0.0+gapCountFG[seqNMer[0,gp]+b+seqNMer[gp+1..-1]]-curExp)/Math.sqrt(curExp)].max();
									supZmin=[supZmin, (0.0+gapCountFG[seqNMer[0,gp]+b+seqNMer[gp+1..-1]]-curExp)/Math.sqrt(curExp)].min();
								end
							}
						end
					end
				}
				if justZScore>0 # if k-mer is enriched
					curKMerData[I_SuperZ_FG]=(supZmax); #use enrichment
				elsif justZScore<0 # if k-mer depleted
					curKMerData[I_SuperZ_FG]=(supZmin); # use depletion
				else # neither enriched nor depleted.
					curKMerData[I_SuperZ_FG]=0.0;
				end
			end
			curKMerData[I_DeltaZ_FG]= (curKMerData[I_SubZ_FG]).abs()-(curKMerData[I_SuperZ_FG]).abs();
			if useBG #superZ with background {
				if bgHits==0 #{
					curKMerData[I_SuperZ_BG]=0.0;
				else #}{
					supZmax=0.0;
					supZmin=0.0;
					alphabet.each{|b| #calc BG super Z
						curExp=(0.0+bgHits)*ntHashBG[b];
						if curExp>0
							supZmax=[supZmax, (0.0+gapCountBG[seqNMer+b]-curExp)/Math.sqrt(curExp),(0.0+gapCountBG[b+seqNMer]-curExp)/Math.sqrt(curExp)].max();
							supZmin=[supZmin, (0.0+gapCountBG[seqNMer+b]-curExp)/Math.sqrt(curExp),(0.0+gapCountBG[b+seqNMer]-curExp)/Math.sqrt(curExp)].min();
						end
						if addGaps # add a base of information to the middle
							1.upto(seqNMer.length()-2){|gp|
								if seqNMer[gp,1]=="-"
									supZmax=[supZmax, (0.0+gapCountBG[seqNMer[0,gp]+b+seqNMer[gp+1..-1]]-curExp)/Math.sqrt(curExp)].max();
									supZmin=[supZmin, (0.0+gapCountBG[seqNMer[0,gp]+b+seqNMer[gp+1..-1]]-curExp)/Math.sqrt(curExp)].min();
								end
							}
						end
					}
					if justZScore>0 # k-mer in FG is enriched
						curKMerData[I_SuperZ_BG] = (supZmax);
					elsif justZScore<0 #depleted
						curKMerData[I_SuperZ_BG] = (supZmin);
					else # neither enriched nor depleted.
						curKMerData[I_SuperZ_BG] = 0.0;
					end
				end #}
				if seqHits==0 #no hits in the FG {
					curKMerData[I_SuperZ_Rel] = 0.0; # because we expect no supermotifs containing this motif in FG.
				elsif bgHits==0 # no hits in BG #}{
					curKMerData[I_SuperZ_Rel] = 0.0; # because we expect no supermotifs containing this motif in BG - nothing to compare to.
				else #}{
					supZmax=0.0;
					supZmin=0.0;
					alphabet.each{|b|
						curExpBG=(0.0+bgHits)*ntHashBG[b];
						curExpSeq=(0.0+seqHits)*ntHash[b];
						if curExpBG!=0 && curExpSeq!=0 # if either is 0, there is a 0 in the %nt hash, so skip it #{
							if curExpBG>curExpSeq
								scaleBG= curExpSeq/curExpBG;
								scaleFG = 1;
								denom = Math.sqrt(curExpSeq);
							else
								scaleBG= 1; #cbg
								scaleFG = curExpBG/curExpSeq; #cq
								denom = Math.sqrt(curExpBG); 
							end
							denom=1.0 if denom==0;
							#((Oq-Eq)*cq-(Obg-Ebg)*cbg)/sqrt(min(Eq,Ebg))
#							begin
							supZmax=[supZmax, ((0.0+gapCountFG[seqNMer+b]-curExpSeq)*scaleFG-(0.0+gapCountBG[seqNMer+b]-curExpBG)*scaleBG)/denom,((0.0+gapCountFG[b+seqNMer]-curExpSeq)*scaleFG-(0.0+gapCountBG[b+seqNMer]-curExpBG)*scaleBG)/denom].max();
							supZmin=[supZmin, ((0.0+gapCountFG[seqNMer+b]-curExpSeq)*scaleFG-(0.0+gapCountBG[seqNMer+b]-curExpBG)*scaleBG)/denom,((0.0+gapCountFG[b+seqNMer]-curExpSeq)*scaleFG-(0.0+gapCountBG[b+seqNMer]-curExpBG)*scaleBG)/denom].min();
							if addGaps # add a base of information to the middle
								1.upto(seqNMer.length()-2){|gp|
									if seqNMer[gp,1]=="-"
										supZmax=[supZmax, ((0.0+gapCountFG[seqNMer[0,gp]+b+seqNMer[gp+1..-1]]-curExpSeq)*scaleFG-(0.0+gapCountBG[seqNMer[0,gp]+b+seqNMer[gp+1..-1]]-curExpBG)*scaleBG)/denom].max();
										supZmin=[supZmin, ((0.0+gapCountFG[seqNMer[0,gp]+b+seqNMer[gp+1..-1]]-curExpSeq)*scaleFG-(0.0+gapCountBG[seqNMer[0,gp]+b+seqNMer[gp+1..-1]]-curExpBG)*scaleBG)/denom].min();
									end
								}
							end
						end #}
					}
					if normZScore>0 # if normalized Z score is enriched
						curKMerData[I_SuperZ_Rel] = (supZmax);
					elsif normZScore<0 # if normalized Z-score is depleted
						curKMerData[I_SuperZ_Rel] = (supZmin);
					else # neither enriched nor depleted.
						curKMerData[I_SuperZ_Rel] = 0.0
					end
				end #}
				curKMerData[I_DeltaZ_Rel]=(curKMerData[I_SubZ_Rel]).abs()-(curKMerData[I_SuperZ_Rel]).abs()
			end #}
		end #}
		allData.push(curKMerData);
	}
	curFGDist=nil;#garbage
}
#} #Benchmark
if (noSort) # sort by sequence
		allData.sort!(){|a,b|
			b[I_SEQ]<=>a[I_SEQ]
		};
else
	print("Sorting results...\n");
	if superZ==1 # sort using superZ and BG
		#print("Sorting results by superZ...\n");
		kPos = dataPositions["k"];#no BG
		sortBy = I_SubZ_FG;#no BG
		filterBy = I_DeltaZ_FG;
		if useBG #
			#print("Sorting results by superZ and BG...\n");
			sortBy = I_SubZ_Rel;
			filterBy = I_DeltaZ_Rel;
		end
		allData.sort!(){|a,b|
			case 
			when a[filterBy]>0 && b[filterBy]<=0 && b[I_K]<maxTreeSize 
				-1
			when a[filterBy]<=0 && a[I_K]<maxTreeSize && b[filterBy]>0 
				1
			else
				b[sortBy].abs() <=> a[sortBy].abs();
			end
		};
	else #no superZ
		#sort by SubZ 
		sortBy = I_SubZ_FG;#no BG
		if useBG #BG
			sortBy = I_SubZ_Rel;
		end
		allData.sort!(){|a,b|
			b[sortBy].abs()<=>a[sortBy].abs()
		};
	end
end
print("Printing results...\n");
outFile = smartGZOut(outFP, "w");
outFile.print(header.join("\t")+"\n");
0.upto(allData.length-1){|i|
	curEntry = allData[i]
	curEntry.map!{|e| e.to_s};
	outFile.print(curEntry.join("\t")+"\n");
	outFile.flush();
}
print("All Done!\n");
outFile.close();
